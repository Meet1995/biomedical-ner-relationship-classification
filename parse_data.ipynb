{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2998eb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8948db1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"data/data_sample/\"\n",
    "file_name = \"164726\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "320904de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_str = None\n",
    "with open(base_path + file_name + \".ann\", \"r\") as file:\n",
    "    ann_str = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2193e11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_entities_relationships(file_content):\n",
    "    \"\"\"\n",
    "    parses out entities and relationships from the entities file\n",
    "    \"\"\"\n",
    "    entities = {}\n",
    "    relationships = {}\n",
    "\n",
    "    for line in file_content.strip().split('\\n'):\n",
    "        cols = line.split('\\t')\n",
    "        identifier = cols[0]\n",
    "\n",
    "        if identifier.startswith('T'):\n",
    "            entity_type, start, end = cols[1].split()\n",
    "            value = cols[2]\n",
    "            entities[identifier] = {'type': entity_type, 'start': int(start), 'end': int(end), 'value': value}\n",
    "\n",
    "        elif identifier.startswith('R'):\n",
    "            relationship_type, arg1, arg2 = cols[1].split()\n",
    "            relationships[identifier] = {'type': relationship_type, 'arg1': arg1.split(':')[1], 'arg2': arg2.split(':')[1]}\n",
    "\n",
    "    return entities, relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "178439db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ent, rel = parse_entities_relationships(ann_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "be3e8ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_str = None\n",
    "with open(base_path + file_name + \".txt\", \"r\") as file:\n",
    "    txt_str = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "85be2fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = sent_tokenize(txt_str)\n",
    "# print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9ad32b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_start_end(sentences):\n",
    "    \"\"\"\n",
    "    get starting and ending positions of sentences\n",
    "    \"\"\"\n",
    "    sent_positions = []\n",
    "    position = 0\n",
    "    for sent in sentences:\n",
    "        start = position\n",
    "        end = position + len(sent)\n",
    "        sent_positions.append((start, end))\n",
    "        position = end + 1\n",
    "    return sent_positions\n",
    "\n",
    "def update_entity_indices(entities, sent_positions):\n",
    "    \"\"\"\n",
    "    for each entity update its position relative to this sentence\n",
    "    \"\"\"\n",
    "    for entity_key in entities:\n",
    "        entity = entities[entity_key]\n",
    "        start = entity['start']\n",
    "        end = entity['end']\n",
    "        for i, (sent_start, sent_end) in enumerate(sent_positions):\n",
    "            if(entity_key == \"T11\"):\n",
    "                print(end, sent_end)\n",
    "            if start >= sent_start and end <= sent_end:\n",
    "                entity['sentence'] = i\n",
    "                entity['sent_start'] = start - sent_start\n",
    "                entity['sent_end'] = end - sent_start\n",
    "                break\n",
    "    return entities\n",
    "                \n",
    "def get_relationship_spans(entities, relationships, txt_str):\n",
    "    \"\"\"\n",
    "    get relationship spans\n",
    "    \"\"\"\n",
    "    sentences = sent_tokenize(txt_str)\n",
    "    entities = update_entity_indices(entities, sentence_start_end(sentences))\n",
    "#     print(entities)\n",
    "    relationship_spans = {}\n",
    "    processed_sentences = set()\n",
    "\n",
    "    for rel_id, relationship in relationships.items():\n",
    "        arg1 = entities[relationship['arg1']]\n",
    "        arg2 = entities[relationship['arg2']]\n",
    "        print(relationship['arg1'], arg1,  \" 1\")\n",
    "        print(relationship['arg2'], arg2, \" 2\")\n",
    "        sent_start = min(arg1['sentence'], arg2['sentence'])\n",
    "        sent_end = max(arg1['sentence'], arg2['sentence'])\n",
    "\n",
    "        span = ' '.join(sentences[sent_start:sent_end+1])\n",
    "        processed_sentences.add(sent_start)\n",
    "        processed_sentences.add(sent_end)\n",
    "\n",
    "        if span not in relationship_spans:\n",
    "            relationship_spans[span] = {\n",
    "                'relationships': [],\n",
    "                'entities': {}\n",
    "            }\n",
    "\n",
    "        relationship_spans[span]['relationships'].append({\n",
    "            'id': rel_id,\n",
    "            'type': relationship['type'],\n",
    "            'arg1': relationship['arg1'],\n",
    "            'arg2': relationship['arg2']\n",
    "        })\n",
    "\n",
    "        relationship_spans[span]['entities'][relationship['arg1']] = arg1\n",
    "        relationship_spans[span]['entities'][relationship['arg2']] = arg2\n",
    "\n",
    "    # Add \"NOREL\" relationships for sentences with two entities and no relations\n",
    "    for i, sent in enumerate(sentences):\n",
    "        if i not in processed_sentences:\n",
    "            entities_in_sent = [e for e in entities.values() if e['sentence'] == i]\n",
    "            if len(entities_in_sent) == 2:\n",
    "                span = sent\n",
    "                e1, e2 = entities_in_sent\n",
    "                relationship_spans[span] = {\n",
    "                    'relationships': [{'id': f'R{i}', 'type': 'NOREL', 'arg1': e1['id'], 'arg2': e2['id']}],\n",
    "                    'entities': {e1['id']: e1, e2['id']: e2}\n",
    "                }\n",
    "\n",
    "    relationship_spans_json = json.dumps(relationship_spans, indent=2)\n",
    "    print(\"Relationship Spans (JSON):\", relationship_spans_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c4c58714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5588 790\n",
      "5588 1006\n",
      "5588 1086\n",
      "5588 1325\n",
      "5588 1375\n",
      "5588 1441\n",
      "5588 1522\n",
      "5588 1563\n",
      "5588 1615\n",
      "5588 1668\n",
      "5588 1710\n",
      "5588 1764\n",
      "5588 1789\n",
      "5588 1822\n",
      "5588 1912\n",
      "5588 2012\n",
      "5588 2296\n",
      "5588 2453\n",
      "5588 2466\n",
      "5588 2492\n",
      "5588 2505\n",
      "5588 2523\n",
      "5588 2536\n",
      "5588 2601\n",
      "5588 2617\n",
      "5588 2643\n",
      "5588 2716\n",
      "5588 2773\n",
      "5588 2819\n",
      "5588 2858\n",
      "5588 2879\n",
      "5588 2901\n",
      "5588 2938\n",
      "5588 2960\n",
      "5588 2983\n",
      "5588 3002\n",
      "5588 3059\n",
      "5588 3088\n",
      "5588 3798\n",
      "5588 3845\n",
      "5588 3913\n",
      "5588 4016\n",
      "5588 4069\n",
      "5588 4096\n",
      "5588 4122\n",
      "5588 4818\n",
      "5588 4890\n",
      "5588 5108\n",
      "5588 5329\n",
      "5588 5405\n",
      "5588 5491\n",
      "5588 5586\n",
      "5588 5739\n",
      "5588 5865\n",
      "5588 5963\n",
      "5588 6042\n",
      "5588 6189\n",
      "5588 6240\n",
      "5588 6316\n",
      "5588 6967\n",
      "5588 7079\n",
      "5588 7173\n",
      "5588 7292\n",
      "5588 7359\n",
      "5588 7384\n",
      "5588 7441\n",
      "T2 {'type': 'Route', 'start': 1376, 'end': 1378, 'value': 'IV', 'sentence': 5, 'sent_start': 0, 'sent_end': 2}  1\n",
      "T3 {'type': 'Drug', 'start': 1379, 'end': 1384, 'value': 'nitro', 'sentence': 5, 'sent_start': 3, 'sent_end': 8}  2\n",
      "T6 {'type': 'Reason', 'start': 5420, 'end': 5428, 'value': 'diuresis', 'sentence': 50, 'sent_start': 14, 'sent_end': 22}  1\n",
      "T8 {'type': 'Drug', 'start': 5437, 'end': 5442, 'value': 'lasix', 'sentence': 50, 'sent_start': 31, 'sent_end': 36}  2\n",
      "T6 {'type': 'Reason', 'start': 5420, 'end': 5428, 'value': 'diuresis', 'sentence': 50, 'sent_start': 14, 'sent_end': 22}  1\n",
      "T9 {'type': 'Drug', 'start': 5447, 'end': 5453, 'value': 'diuril', 'sentence': 50, 'sent_start': 41, 'sent_end': 47}  2\n",
      "T7 {'type': 'Route', 'start': 5434, 'end': 5436, 'value': 'IV', 'sentence': 50, 'sent_start': 28, 'sent_end': 30}  1\n",
      "T8 {'type': 'Drug', 'start': 5437, 'end': 5442, 'value': 'lasix', 'sentence': 50, 'sent_start': 31, 'sent_end': 36}  2\n",
      "T7 {'type': 'Route', 'start': 5434, 'end': 5436, 'value': 'IV', 'sentence': 50, 'sent_start': 28, 'sent_end': 30}  1\n",
      "T9 {'type': 'Drug', 'start': 5447, 'end': 5453, 'value': 'diuril', 'sentence': 50, 'sent_start': 41, 'sent_end': 47}  2\n",
      "T10 {'type': 'Reason', 'start': 5524, 'end': 5548, 'value': 'hemodynamically unstable', 'sentence': 51, 'sent_start': 32, 'sent_end': 56}  1\n",
      "T11 {'type': 'Drug', 'start': 5580, 'end': 5588, 'value': 'dopamine'}  2\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'sentence'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m spans \u001b[38;5;241m=\u001b[39m get_relationship_spans(ent, rel, txt_str)\n",
      "Cell \u001b[0;32mIn[84], line 47\u001b[0m, in \u001b[0;36mget_relationship_spans\u001b[0;34m(entities, relationships, txt_str)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(relationship[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marg1\u001b[39m\u001b[38;5;124m'\u001b[39m], arg1,  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m 1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(relationship[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marg2\u001b[39m\u001b[38;5;124m'\u001b[39m], arg2, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m 2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m sent_start \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(arg1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m'\u001b[39m], arg2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     48\u001b[0m sent_end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(arg1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m'\u001b[39m], arg2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     50\u001b[0m span \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(sentences[sent_start:sent_end\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sentence'"
     ]
    }
   ],
   "source": [
    "spans = get_relationship_spans(ent, rel, txt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "908ef754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'IV nitro inititated,\\nheparin, aspirin initiated and now painfree.': {'type': 'Route-Drug', 'text': 'IV nitro inititated,\\nheparin, aspirin initiated and now painfree.', 'arg1': {'id': 'T2', 'type': 'Route', 'value': 'IV', 'start': 0, 'end': 2}, 'arg2': {'id': 'T3', 'type': 'Drug', 'value': 'nitro', 'start': 3, 'end': 8}}}\n"
     ]
    }
   ],
   "source": [
    "print(spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e6de46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
