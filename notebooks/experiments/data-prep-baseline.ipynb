{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "pd.set_option(\"display.max.columns\", None)\n",
    "pd.set_option(\"display.max.rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../../data/parsed_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ner_train = pd.read_parquet(f\"{DATA_PATH}/ner_train.parquet\")\n",
    "df_rel_train = pd.read_parquet(f\"{DATA_PATH}/rel_train.parquet\")\n",
    "\n",
    "df_ner_test = pd.read_parquet(f\"{DATA_PATH}/ner_test.parquet\")\n",
    "df_rel_test = pd.read_parquet(f\"{DATA_PATH}/rel_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_tags(df):\n",
    "    df['pos'] = df.groupby(\n",
    "        ['uid', 'contains_rel', 'sid']\n",
    "    )['token'].transform(lambda s: [x[1] for x in nltk.pos_tag(s)])\n",
    "    return df\n",
    "\n",
    "\n",
    "def extract_group_feats(df, window=2):\n",
    "    df_feats = df.copy()\n",
    "    df_feats['pos'] = df_feats['pos'].astype('string')\n",
    "    df_feats['istitle'] = df_feats['token'].str.istitle().astype('string')\n",
    "    df_feats['isupper'] = df_feats['token'].str.isupper().astype('string')\n",
    "    df_feats['isalpha'] = df_feats['token'].str.isalpha().astype('string')\n",
    "    df_feats['isnumeric'] = df_feats['token'].str.isnumeric().astype('string')\n",
    "    df_feats['containsnumbers'] = df_feats['token'].apply(\n",
    "        lambda x: len(re.findall(r'\\d', x))>0\n",
    "        ).astype('string')\n",
    "    df_feats = df_feats.drop(columns=['uid', 'contains_rel', 'sid'])\n",
    "    df_feats = df_feats.set_index(['token', 'tag'])\n",
    "    ini_cols = df_feats.columns\n",
    "    for s in range(-window, window+1):\n",
    "        if s != 0:\n",
    "            cols = [f\"{s}_{c}\" for c in ini_cols]\n",
    "            shift_df = df_feats[ini_cols].shift(-s)\n",
    "            shift_df.columns = cols\n",
    "            df_feats = pd.concat([df_feats, shift_df], axis=1)\n",
    "    return df_feats\n",
    "\n",
    "\n",
    "def extract_feats(df_ner):\n",
    "    df_ner = get_pos_tags(df_ner)\n",
    "    return df_ner.groupby(['uid', 'contains_rel', 'sid']).progress_apply(\n",
    "        extract_group_feats\n",
    "    )\n",
    "\n",
    "\n",
    "def get_dependency_graph(token_lst, spacy_pipe):\n",
    "    doc = spacy_pipe(\" \".join(token_lst))\n",
    "    edges = []\n",
    "    for token in doc:\n",
    "        for child in token.children:\n",
    "            edges.append((token.text, child.text))\n",
    "    return nx.from_edgelist(edges)\n",
    "\n",
    "\n",
    "def get_sdp(token_lst, s_idx, t_idx, spacy_pipe):\n",
    "    source = token_lst[s_idx]\n",
    "    target = token_lst[t_idx]\n",
    "    selected_tokens = token_lst[: max(s_idx, t_idx) + 1]\n",
    "    g = get_dependency_graph(selected_tokens, spacy_pipe)\n",
    "    try:\n",
    "        sdp = \" \".join(nx.shortest_path(g, source=source, target=target))\n",
    "    except Exception as e:\n",
    "        # print(e)\n",
    "        sdp = \" \".join(selected_tokens)\n",
    "    return sdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "008f1f7111a94fe0ad690f07d53b2459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39367 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ner_train = extract_feats(df_ner_train)\n",
    "df_ner_train.to_parquet(f\"{DATA_PATH}/ner_train_baseline.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "565d5e8834684f868b4887d88d465985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25417 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ner_test = extract_feats(df_ner_test)\n",
    "df_ner_test.to_parquet(f\"{DATA_PATH}/ner_test_baseline.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622670c3bac549b084c85ac6dec20197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36346 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_rel_train['sdp'] = df_rel_train.progress_apply(\n",
    "    lambda row: get_sdp(\n",
    "        row['text'].split('|'),\n",
    "        int(row['arg1'].split(':')[:-1][0]),\n",
    "        int(row['arg2'].split(':')[:-1][-1]),\n",
    "        nlp\n",
    "    ), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rel_train.to_parquet(f\"{DATA_PATH}/rel_train_baseline.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8b208859cd48a6a006ebdd256f988d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_rel_test['sdp'] = df_rel_test.progress_apply(\n",
    "    lambda row: get_sdp(\n",
    "        row['text'].split('|'),\n",
    "        int(row['arg1'].split(':')[:-1][0]),\n",
    "        int(row['arg2'].split(':')[:-1][-1]),\n",
    "        nlp\n",
    "    ), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rel_test.to_parquet(f\"{DATA_PATH}/rel_test_baseline.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
