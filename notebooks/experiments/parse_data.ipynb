{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2998eb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2193e11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_entities_relationships(file_content):\n",
    "    \"\"\"\n",
    "    parses out entities and relationships from the entities file\n",
    "    \"\"\"\n",
    "    entities = {}\n",
    "    relationships = {}\n",
    "\n",
    "    for line in file_content.strip().split('\\n'):\n",
    "        cols = line.split('\\t')\n",
    "        identifier = cols[0]\n",
    "\n",
    "        if \"Arg1:\" in cols[1]:\n",
    "            relationship_type, arg1, arg2 = cols[1].split()\n",
    "            relationships[identifier] = {\n",
    "                'type': relationship_type,\n",
    "                'arg1': arg1.split(':')[1],\n",
    "                'arg2': arg2.split(':')[1]\n",
    "            }\n",
    "            \n",
    "        else:\n",
    "            split_cols = cols[1].split()\n",
    "            entity_type = split_cols[0]\n",
    "            value = cols[2]\n",
    "            start = split_cols[1]\n",
    "            end = split_cols[-1]\n",
    "            entities[identifier] = {\n",
    "                'type': entity_type,\n",
    "                'start': int(start),\n",
    "                'end': int(end),\n",
    "                'value': value\n",
    "            }\n",
    "\n",
    "    return entities, relationships\n",
    "\n",
    "\n",
    "def sentence_start_end(sentences, txt_str):\n",
    "    \"\"\"\n",
    "    get starting and ending positions of sentences\n",
    "    \"\"\"\n",
    "    curr_start = 0\n",
    "    sent_positions = []\n",
    "    for i in range(len(sentences)):\n",
    "        sent = sentences[i]\n",
    "        match_idx = txt_str.find(sent, curr_start)\n",
    "        start = match_idx\n",
    "        end = match_idx + len(sent)\n",
    "        curr_start = end\n",
    "        sent_positions.append((start, end))\n",
    "    return sent_positions\n",
    "\n",
    "\n",
    "def update_entity_indices(entities, sent_positions):\n",
    "    \"\"\"\n",
    "    for each entity update its position relative to this sentence\n",
    "    \"\"\"\n",
    "    for entity_key in entities:\n",
    "        entity = entities[entity_key]\n",
    "        start = entity['start']\n",
    "        end = entity['end']\n",
    "        for i, (sent_start, sent_end) in enumerate(sent_positions):\n",
    "            if start >= sent_start and end <= sent_end:\n",
    "                entity['sentence'] = i\n",
    "                entity['sent_start'] = start - sent_start\n",
    "                entity['sent_end'] = end - sent_start\n",
    "                break\n",
    "    return entities\n",
    "\n",
    "\n",
    "def get_relationship_spans(entities, relationships, txt_str):\n",
    "    \"\"\"\n",
    "    get relationship spans\n",
    "    \"\"\"\n",
    "    sentences = sent_tokenize(txt_str)\n",
    "    entities = update_entity_indices(entities, sentence_start_end(sentences, txt_str))\n",
    "\n",
    "    relationship_spans = {}\n",
    "\n",
    "    for rel_id, relationship in relationships.items():\n",
    "        arg1 = entities[relationship['arg1']]\n",
    "        arg2 = entities[relationship['arg2']]\n",
    "        if arg1['sentence'] <= arg2['sentence']:\n",
    "            sent_start = arg1['sentence']\n",
    "            sent_end = arg2['sentence']\n",
    "            arg1_start = arg1['sent_start']\n",
    "            arg1_end = arg1['sent_end']\n",
    "            offset = len(' '.join(sentences[sent_start: sent_end]))\n",
    "            arg2_start = offset + arg2['sent_start']\n",
    "            arg2_end = offset + arg2['sent_end']\n",
    "        else:\n",
    "            sent_start = arg2['sentence']\n",
    "            sent_end = arg1['sentence']\n",
    "            arg2_start = arg2['sent_start']\n",
    "            arg2_end = arg2['sent_end']\n",
    "            offset = len(' '.join(sentences[sent_start: sent_end]))\n",
    "            arg1_start = offset + arg1['sent_start']\n",
    "            arg1_end = offset + arg1['sent_end']\n",
    "        \n",
    "        span = ' '.join(sentences[sent_start:sent_end+1])\n",
    "        \n",
    "#         print(len(span[arg1_start:arg1_end]), len(arg1['value']))\n",
    "#         print(span[arg1_start:arg1_end], arg1['value'])\n",
    "#         print(len(span[arg2_start:arg2_end]), len(arg2['value']))\n",
    "#         print(span[arg2_start:arg2_end], arg2['value'])\n",
    "#         assert (\n",
    "#             (span[arg1_start:arg1_end] == arg1['value']) and \n",
    "#             (span[arg2_start:arg2_end] == arg2['value'])\n",
    "#         )\n",
    "\n",
    "        if span not in relationship_spans:\n",
    "            relationship_spans[span] = {\n",
    "                'relationships': {},\n",
    "                'all_entities': {}\n",
    "            }\n",
    "\n",
    "        relationship_spans[span]['relationships'][rel_id] = {\n",
    "            'type': relationship['type'],\n",
    "            'arg1': relationship['arg1'],\n",
    "            'arg1_start': arg1_start,\n",
    "            'arg1_end': arg1_end,\n",
    "            'arg2': relationship['arg2'],\n",
    "            'arg2_start': arg2_start,\n",
    "            'arg2_end': arg2_end\n",
    "        }\n",
    "        if relationship['arg1'] not in relationship_spans[span]['all_entities']:\n",
    "            ent_data = {\n",
    "                'start_pos': arg1_start,\n",
    "                'end_pos': arg1_end,\n",
    "                'text': arg1['value'],\n",
    "                'type': arg1['type']\n",
    "            }\n",
    "            relationship_spans[span]['all_entities'][relationship['arg1']] = ent_data\n",
    "        \n",
    "        if relationship['arg2'] not in relationship_spans[span]['all_entities']:\n",
    "            ent_data = {\n",
    "                'start_pos': arg2_start,\n",
    "                'end_pos': arg2_end,\n",
    "                'text': arg2['value'],\n",
    "                'type': arg2['type']\n",
    "            }\n",
    "            relationship_spans[span]['all_entities'][relationship['arg2']] = ent_data\n",
    "    return relationship_spans\n",
    "\n",
    "\n",
    "def get_uncovered_entity_spans(entities_map, relations, txt_str):\n",
    "    sentences = sent_tokenize(txt_str)\n",
    "    updated_entities = update_entity_indices(\n",
    "        entities_map, sentence_start_end(sentences, txt_str)\n",
    "    )\n",
    "    ents_covered = set()\n",
    "    for v in relations.values():\n",
    "        ents_covered = ents_covered.union({v['arg1']}).union({v['arg2']})\n",
    "        \n",
    "    uncovered_dict = {k:v for k, v in updated_entities.items() if k not in ents_covered}\n",
    "\n",
    "    spans = {}\n",
    "    for ent, loc in uncovered_dict.items():\n",
    "        sent = sentences[loc['sentence']]\n",
    "        if sent not in spans:\n",
    "            spans[sent] = {}\n",
    "            \n",
    "        ent_data = {\n",
    "            'start_pos': loc['sent_start'],\n",
    "            'end_pos': loc['sent_end'],\n",
    "            'text': loc['value'],\n",
    "            'type': loc['type']\n",
    "        }\n",
    "        spans[sent][ent] = ent_data\n",
    "    return spans\n",
    "\n",
    "\n",
    "def tag_index(text, ent_type, ent_text, ent_loc):\n",
    "    index_tag_map = {}\n",
    "    tokens = np.array(nltk.word_tokenize(text))\n",
    "    ent_tokens = nltk.word_tokenize(ent_text)\n",
    "    possible_loc = np.where(tokens==ent_tokens[0])[0]\n",
    "    ent_start_loc = possible_loc[np.argmin(\n",
    "        [abs(ent_loc - len(' '.join(tokens[0:x]))) for x in possible_loc]\n",
    "    )]\n",
    "    ent_end_loc = ent_start_loc + len(ent_tokens) - 1\n",
    "    if len(ent_tokens) == 1:\n",
    "        index_tag_map[ent_start_loc] = f\"S-{ent_type}\"\n",
    "    else:\n",
    "        for i in range(ent_start_loc, ent_end_loc):\n",
    "            if i == ent_start_loc:\n",
    "                index_tag_map[i] = f\"B-{ent_type}\"\n",
    "            elif i == ent_end_loc - 1:\n",
    "                index_tag_map[i] = f\"E-{ent_type}\"\n",
    "            else:\n",
    "                index_tag_map[i] = f\"I-{ent_type}\"\n",
    "    return index_tag_map, ent_start_loc, ent_end_loc\n",
    "\n",
    "\n",
    "def get_token_tags(text, all_ents, all_rels=None):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tags = ['O'] * len(tokens)\n",
    "    tag_dict = {}\n",
    "    ent_dict = {}\n",
    "    for eid, val in all_ents.items():\n",
    "        tmp, s_idx, e_idx = tag_index(\n",
    "            text, val['type'], val['text'], val['start_pos']\n",
    "        )\n",
    "        tag_dict = tag_dict | tmp\n",
    "        ent_dict[eid] = {\n",
    "            'start_idx': s_idx,\n",
    "            'end_idx': e_idx\n",
    "        }\n",
    "    for i, t in tag_dict.items():\n",
    "        tags[i] = t\n",
    "        \n",
    "    if all_rels:\n",
    "        rels = all_rels.copy()\n",
    "        rel_lst = []\n",
    "        for _, rdata in rels.items():\n",
    "            tokens_str = \"|\".join(tokens)\n",
    "            arg1_idx = (f\"{ent_dict[rdata['arg1']]['start_idx']}\"\n",
    "            f\":{ent_dict[rdata['arg1']]['end_idx']}\")\n",
    "            arg2_idx = (f\"{ent_dict[rdata['arg1']]['start_idx']}\"\n",
    "            f\":{ent_dict[rdata['arg1']]['end_idx']}\")\n",
    "            rel_lst.append([tokens_str, arg1_idx, arg2_idx])\n",
    "        \n",
    "        ner_df = pd.DataFrame(\n",
    "            list(zip(tokens, tags)), columns=['token', 'tag']\n",
    "        ) \n",
    "        rels_df = pd.DataFrame(rel_lst, columns=['text', 'arg1', 'arg2'])\n",
    "        return ner_df, rels_df\n",
    "    else:\n",
    "        ner_df = pd.DataFrame(\n",
    "            list(zip(tokens, tags)), columns=['token', 'tag']\n",
    "        ) \n",
    "        return ner_df\n",
    "\n",
    "def parse_data(path):\n",
    "    anns = sorted(glob.glob(f\"{path}./*.ann\"))\n",
    "    files = sorted(glob.glob(f\"{path}./*.txt\"))\n",
    "    df1_lst = []\n",
    "    df2_lst = []\n",
    "    for a, f in zip(anns, files):\n",
    "        idx = a.split('\\\\')[-1].split('.')[0]\n",
    "        assert idx == f.split('\\\\')[-1].split('.')[0]\n",
    "        with open(a, 'r') as a_f:\n",
    "            ann_str = a_f.read()\n",
    "        with open(f, 'r') as f_f:\n",
    "            txt_str = f_f.read()\n",
    "        try:\n",
    "            ent, rel = parse_entities_relationships(ann_str)\n",
    "            rel_spans = get_relationship_spans(ent, rel, txt_str)\n",
    "        except Exception as e:\n",
    "            print(idx)\n",
    "            raise ValueError\n",
    "        df_ner_lst = []\n",
    "        df_rel_lst = []\n",
    "        tmp = []\n",
    "        for i, (s, v) in enumerate(rel_spans.items()):\n",
    "            try:\n",
    "                df1, df2 = get_token_tags(s, v['all_entities'], v['relationships'])\n",
    "                df1['sid'] = i\n",
    "                df1['contains_rel'] = 1\n",
    "                df2['sid'] = i\n",
    "                df_ner_lst.append(df1)\n",
    "                df_rel_lst.append(df2)\n",
    "            except:\n",
    "                print(f\"{idx}: {s}\")\n",
    "                tmp.append((s, v))\n",
    "        uncovered_ent_spans = get_uncovered_entity_spans(ent, rel, txt_str)\n",
    "        for i, (s, v) in enumerate(uncovered_ent_spans.items()):\n",
    "            try:\n",
    "                df1 = get_token_tags(s, v)\n",
    "                df1['sid'] = i\n",
    "                df1['contains_rel'] = 0\n",
    "                df_ner_lst.append(df1)\n",
    "            except:\n",
    "                print(f\"{idx}: {s}\")\n",
    "                tmp.append((s, v))\n",
    "        df_ner_per_rec = pd.concat(df_ner_lst)\n",
    "        df_ner_per_rec['uid'] = idx\n",
    "        df1_lst.append(df_ner_per_rec)\n",
    "        df_rel_per_rec = pd.concat(df_rel_lst)\n",
    "        df_rel_per_rec['uid'] = idx\n",
    "        df2_lst.append(df_rel_per_rec)\n",
    "\n",
    "    df_ner = pd.concat(df1_lst)\n",
    "    df_rel = pd.concat(df2_lst)\n",
    "    return df_ner, df_rel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d04324cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ent, rel = parse_entities_relationships(ann_str)\n",
    "rel_spans = get_relationship_spans(ent, rel, txt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "00bfb984",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ner_lst = []\n",
    "df_rel_lst = []\n",
    "tmp = []\n",
    "# for i, (s, v) in enumerate(rel_spans.items()):\n",
    "#     try:\n",
    "#         df1, df2 = get_token_tags(s, v['all_entities'], v['relationships'])\n",
    "#         df1['sid'] = i\n",
    "#         df1['contains_rel'] = 1\n",
    "#         df2['sid'] = i\n",
    "#         df_ner_lst.append(df1)\n",
    "#         df_rel_lst.append(df2)\n",
    "#     except Exception as e:\n",
    "#         print(\"*****\")\n",
    "#         print(e)\n",
    "#         print(\"*****\")\n",
    "#         print(f\"{100035}: {s}\")\n",
    "#         tmp.append((s, v))\n",
    "\n",
    "for i, (s, v) in enumerate(uncovered_ent_spans.items()):\n",
    "    try:\n",
    "        df1 = get_token_tags(s, v)\n",
    "        df1['sid'] = i\n",
    "        df1['contains_rel'] = 0\n",
    "        df_ner_lst.append(df1)\n",
    "    except Exception as e:\n",
    "        print(\"*****\")\n",
    "        print(e)\n",
    "        print(\"*****\")\n",
    "        print(f\"{100035}: {s}\")\n",
    "        tmp.append((s, v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "44a9fbe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('seizures', 'ns eizure medication')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[-1][0][58:66], tmp[-1][0][106:126]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e3b89e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Your mental status\\nslowly improved, though you did have 2 seizures, last on [**3-18**]. You were started ons eizure medications for this.',\n",
       " {'relationships': {'R283': {'type': 'Reason-Drug',\n",
       "    'arg1': 'T340',\n",
       "    'arg1_start': 58,\n",
       "    'arg1_end': 66,\n",
       "    'arg2': 'T341',\n",
       "    'arg2_start': 106,\n",
       "    'arg2_end': 126}},\n",
       "  'all_entities': {'T340': {'start_pos': 58,\n",
       "    'end_pos': 66,\n",
       "    'text': 'seizures',\n",
       "    'type': 'Reason'},\n",
       "   'T341': {'start_pos': 106,\n",
       "    'end_pos': 126,\n",
       "    'text': 's eizure medications',\n",
       "    'type': 'Drug'}}})"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c843f28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('aggitated', 'Topiramate')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[16:25], s[56:66]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "20a5fc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncovered_ent_spans = get_uncovered_entity_spans(ent, rel, txt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a11075c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100035: # Ventilator associated pneumonia:  Patient developed a fever on\n",
      "[**2-27**] with new infiltrates on chest xray while intubated. He was\n",
      "initially covered with vanc/cefepime and cipro.\n",
      "100035: He completed an 8 day course of\n",
      "Vanco/Cefepime.\n",
      "100035: 3. acetaminophen 325 mg Tablet Sig: Two (2) Tablet PO Q6H (every\n",
      "6 hours) as needed for pain/fever.\n",
      "100035: 11. acetaminophen 500 mg Tablet Sig: Two (2) Tablet PO TID (3\n",
      "times a day) as needed for pain/fever.\n",
      "100035: Your mental status\n",
      "slowly improved, though you did have 2 seizures, last on [**3-18**]. You were started ons eizure medications for this.\n",
      "100039: Brief Hospital Course:\n",
      "38 yo F w/ h/o ALL in remission s/p cord transplant in [**1-13**],\n",
      "anthracycline-induced cardiomyopathy (EF 15-20% [**1-14**]) and\n",
      "recurrent nausea and vomiting who presents with 1 week abd pain,\n",
      "acute on chronic renal failure and new hyperbilirubinemia.\n",
      "100039: # Anthracycline-induced/ GVHD cardiomyopathy:  EF <20% on echo\n",
      "from 2/[**2174**].\n",
      "100039: She was then taken to the Cath lab and placed\n",
      "on a milrinone/lasix gtt and transfered to the CCU.\n",
      "100039: She was then taken to the Cath lab and placed\n",
      "on a milrinone/lasix gtt and transfered to the CCU. Her volume\n",
      "overload slowly improved and her peripheral edema/ascites slowly\n",
      "improved as well.\n",
      "100039: She was sent to the cath lab and started on a\n",
      "milrinone/lasix gtt and transfered to the CCU with a goal\n",
      "diuresis of 1L per day.\n",
      "100039: - underwent phase I induction with daunorubicin, vincristine,\n",
      "dexamethasone, L-asparaginase, MTX; phase II with\n",
      "cyclophosphamide, cytarabine, mercaptopurine, MTX\n",
      "- Bone Marrow Aspirate/Biopsy on [**2172-10-26**] showed no morphologic\n",
      "\n",
      "evidence of residual leukemia\n",
      "- underwent allo double cord blood SCT [**2173-1-11**], course\n",
      "complicated by neutropenic fever and acute skin GVHD\n",
      "\n",
      "OTHER MEDICAL HISTORY:\n",
      "- Embolic stroke in [**3-/2174**] on coumadin\n",
      "- Cardiomyopathy due to early anthracycline-related\n",
      "cardiotoxicity [**10/2172**]\n",
      "- Chronic kidney disease stage III/IV, baseline creatinine\n",
      "~2.0-2.2\n",
      "- Asthma\n",
      "- HTN\n",
      "- Cervical Intraepithelial neoplasia\n",
      "- C-section in [**2165**]\n",
      "\n",
      "\n",
      "Social History:\n",
      "Smoke: never\n",
      "EtOH: Occasional in past, none currently\n",
      "Drugs: Never\n",
      "Lives/works: Single, has two children (ages 7 and 18).\n",
      "100039: We made the following changes to your medications:\n",
      "-Mycophenolate Mofetil 1000mg twice a day was started\n",
      "-Prednisone 60mg daily was started\n",
      "-Coumadin was decreased to 2mg daily\n",
      "-Torsemide was increased to 40mg daily\n",
      "-Please hold your valsartan until you see your cardiologist\n",
      "-Metoprolol succinate 100mg daily was started; please stop\n",
      "carvedilol\n",
      "-Bentyl (dicyclomine) was started for your abdominal pain\n",
      "-Simethicone was started for abdominal discomfort/gas\n",
      "-Your morphine was switched to long-acting Morphine 15mg twice a\n",
      "day\n",
      "-Bactrim single strength, 1 tablet daily, was started to help\n",
      "prevent infection\n",
      "-Acyclovir 400mg twice a day was started to help prevent\n",
      "infection\n",
      "-Allopurinol 100mg daily was started because your uric acid\n",
      "levels were high\n",
      "\n",
      "Weigh yourself every morning, [**Name8 (MD) 138**] MD if weight goes up more\n",
      "than 3 lbs.\n",
      "100039: Admission Date:  [**2174-4-18**]              Discharge Date:   [**2174-5-17**]\n",
      "\n",
      "Date of Birth:  [**2135-11-15**]             Sex:   F\n",
      "\n",
      "Service: MEDICINE\n",
      "\n",
      "Allergies:\n",
      "Prochlorperazine / Heparin Agents\n",
      "\n",
      "Attending:[**First Name3 (LF) 3918**]\n",
      "Chief Complaint:\n",
      "Abdominal Pain\n",
      "\n",
      "Major Surgical or Invasive Procedure:\n",
      "Upper GI series with small bowel follow through\n",
      "Right heart catheterization\n",
      "IR guided paracentesis\n",
      "\n",
      "\n",
      "History of Present Illness:\n",
      "38 yo F w/ h/o ALL in remission s/p cord transplant in [**1-13**],\n",
      "anthracycline-induced cardiomyopathy (EF 15-20% [**1-14**]) and\n",
      "recurrent nausea and vomiting who presents with abdominal pain,\n",
      "N/V x1 week\n",
      "\n",
      "Of note, the pt was admitted here from [**Date range (1) **] with nausea and\n",
      "vomitting of unclear etiology.\n",
      "100187\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[140], line 242\u001b[0m, in \u001b[0;36mparse_data\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    241\u001b[0m     ent, rel \u001b[39m=\u001b[39m parse_entities_relationships(ann_str)\n\u001b[1;32m--> 242\u001b[0m     rel_spans \u001b[39m=\u001b[39m get_relationship_spans(ent, rel, txt_str)\n\u001b[0;32m    243\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "Cell \u001b[1;32mIn[140], line 77\u001b[0m, in \u001b[0;36mget_relationship_spans\u001b[1;34m(entities, relationships, txt_str)\u001b[0m\n\u001b[0;32m     76\u001b[0m arg2 \u001b[39m=\u001b[39m entities[relationship[\u001b[39m'\u001b[39m\u001b[39marg2\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m---> 77\u001b[0m \u001b[39mif\u001b[39;00m arg1[\u001b[39m'\u001b[39;49m\u001b[39msentence\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m arg2[\u001b[39m'\u001b[39m\u001b[39msentence\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m     78\u001b[0m     sent_start \u001b[39m=\u001b[39m arg1[\u001b[39m'\u001b[39m\u001b[39msentence\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'sentence'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[141], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m parse_data(\u001b[39m\"\u001b[39;49m\u001b[39m../../data/training/\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[140], line 245\u001b[0m, in \u001b[0;36mparse_data\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    244\u001b[0m     \u001b[39mprint\u001b[39m(idx)\n\u001b[1;32m--> 245\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m\n\u001b[0;32m    246\u001b[0m df_ner_lst \u001b[39m=\u001b[39m []\n\u001b[0;32m    247\u001b[0m df_rel_lst \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parse_data(\"../../data/training/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "28fb9d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"../../data/training/100187.ann\"\n",
    "f = \"../../data/training/100187.txt\"\n",
    "with open(a, 'r') as a_f:\n",
    "    ann_str = a_f.read()\n",
    "with open(f, 'r') as f_f:\n",
    "    txt_str = f_f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "178439db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ent, rel = parse_entities_relationships(ann_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "bbc72f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Admission Date:  [**2107-1-17**]              Discharge Date:   [**2107-2-12**]\n",
      "\n",
      "Date of Birth:  [**2042-4-4**]             Sex:   F\n",
      "\n",
      "Service: MEDICINE\n",
      "\n",
      "Allergies:\n",
      "Keflex / Penicillins / Erythromycin Base / Demerol / Ceclor\n",
      "\n",
      "Attending:[**First Name3 (LF) 2932**]\n",
      "Chief Complaint:\n",
      "SOB\n",
      "\n",
      "Major Surgical or Invasive Procedure:\n",
      "None.\n",
      "\n",
      "\n",
      "History of Present Illness:\n",
      "64 yo woman w/ h/o recurrent PEs s/[**Initials (NamePattern4) **] [**Last Name (NamePattern4) 260**] filter, GIB\n",
      "while anticoagulated, COPD, who was discharged [**2107-1-12**] after\n",
      "being treated for new PE presented to the ED with SOB and\n",
      "productive cough. She was readmitted [**2107-1-17**] after she was\n",
      "found to have a multifocal pneumonia and was treated with\n",
      "Levo/Flagyl and Vanco. Cultures were positive for MRSA. Levo and\n",
      "Flagyl were continued for suspected aspiration PNA. The pt\n",
      "recovered quickly over since admission and she is now back on\n",
      "her home O2 requirement. She was getting bridged for her\n",
      "anticoagulation with Lovenox starting [**1-18**] in preparation for\n",
      "discharge.  However, she developed severe abdominal pain and a\n",
      "palpable mass in her L abdomen. A CT was showed a new large\n",
      "hematoma in the muscles of the left anterior and lateral lower\n",
      "abdominal and pelvic wall, without any intraperitoneal or\n",
      "retroperitoneal extent, but with associated mass effect on the\n",
      "lower abdominal and pelvic bowel loops. Surgery was [**Month/Year (2) 4221**]\n",
      "and suggested no intervention, but monitoring for now. HCT\n",
      "dropped 6 points in this setting, but she remained\n",
      "hemodynamically stable with tachycardia which has been present\n",
      "throughout her hospital stay (95-115).\n",
      "\n",
      "She required a total of 5 units PRBC and 4 units FFP\n",
      "transfusions and was transferred to the MICU for further\n",
      "monitoring.  Her hematocrit has since been stable with serial\n",
      "checks.\n",
      ".\n",
      "ROS: She has baseline left to mid chest pain with exertion that\n",
      "is not currently bothering her. She denies current chest pain,\n",
      "SOB, dysuria, increased urinary frequency. She has stable R knee\n",
      "pain.\n",
      "\n",
      "\n",
      "Past Medical History:\n",
      "1. H/O Rheumatic Fever - age 8 -dx'ed last year with rheumatic\n",
      "heart disease per pt (states ED diagnosed this) and has had\n",
      "syndenham chorea\n",
      "2. ?CHF per pt. although [**12-13**] Echo revealed low normal LVEF,\n",
      "mildly thickened aortic and mitral valves with mild MR [**First Name (Titles) **] [**Last Name (Titles) **].\n",
      "\n",
      "3. Orthostatic hypotension\n",
      "4. Chest pain - nearly monthly visits to ED with negative\n",
      "ischemic w/u in the past\n",
      "5. Duodenal/gastric ulcer\n",
      "6. Seven miscarriages\n",
      "7. Ulcerative colitis\n",
      "8. Diverticulosis-s/p colostomy and reversal colostomy-had\n",
      "Colonoscopy [**1-12**] showed only diverticuli without e/o active\n",
      "bleed\n",
      "8. Panic attacks x 15 yrs\n",
      "9. Depression - several SA in past\n",
      "10. Schizoaffective disorder\n",
      "11. h/o polysubstance abuse\n",
      "12. Iron deficiency anemia (baseline unclear-high 20's to 30's)\n",
      "\n",
      "13. COPD\n",
      "14. PE [**7-13**], c/b GIB while on anticoagulation, s/[**Initials (NamePattern4) **] [**Last Name (NamePattern4) 260**]\n",
      "filter. New PE on [**2107-1-2**], again on anticoagulation\n",
      "\n",
      "\n",
      "Social History:\n",
      "Lives in lodge house. She has a homemaker help with her\n",
      "cleaning. She gets meals on wheels. She has very limited funds.\n",
      "Smoked 2 PPD X 40 yrs, quit smoking 4 months ago. Former\n",
      "drinker, reports drinking two 6 packs per day for 2 yrs; quit 27\n",
      "yrs ago. Denies h/o illicits and IVDA. H/O domestic violence.\n",
      "\n",
      "Family History:\n",
      "Daughter -40 - colitis. Had 6 siblings. One sister died, 35,\n",
      "ovarian CA. Brother, died at 48, stroke. Sister, died at 64 from\n",
      "infection. Father died at 65 of MI. Mom was \"psychotic\", died of\n",
      "stroke at 93\n",
      "\n",
      "Physical Exam:\n",
      "VS: 97.6 HR 114, Bp 118/74 RR 20-30 Sats 98% 2L.\n",
      "Gen: NAD, pleasant\n",
      "HEENT: PEERLA, MMM.\n",
      "Neck: supple, no LAD\n",
      "Lungs: moderate air movement, decreased breath sounds at bases\n",
      "CV: RRR, S1S2 present, distant heart sounds, no murmurs\n",
      "Abd: +BS, S/ND, + umbilical hernia, ulcer mid abdomen-reportedly\n",
      "chronic, unchanged, mildy errythematous base. no secretions.\n",
      "Tenderness in L abdomen, palpable mass over unclear extension,\n",
      "no guarding, no rebound\n",
      "Back: no CVA tenderness.\n",
      "Ext: 2+ on RLE, 1+ edema LLE/ no c/c/ 1+ DP\n",
      "Neuro: A&Ox3, CN II-XII intact. moving all extremities.\n",
      "\n",
      "Pertinent Results:\n",
      "ADMISSION LABS:\n",
      "[**2107-1-16**] 08:40PM   PT-87.9* PTT-41.3* INR(PT)-11.8*\n",
      "[**2107-1-16**] 08:40PM   WBC-16.2*# RBC-3.63* HGB-11.6* HCT-33.5*\n",
      "MCV-93 MCH-32.1* MCHC-34.7 RDW-14.0\n",
      "[**2107-1-16**] 08:40PM   NEUTS-90.5* BANDS-0 LYMPHS-4.7* MONOS-2.4\n",
      "EOS-2.0 BASOS-0.5\n",
      "[**2107-1-16**] 08:40PM   GLUCOSE-127* UREA N-16 CREAT-1.0 SODIUM-136\n",
      "POTASSIUM-3.9 CHLORIDE-98 TOTAL CO2-29 ANION GAP-13\n",
      "[**2107-1-16**] 11:00PM URINE  BLOOD-NEG NITRITE-NEG PROTEIN-NEG\n",
      "GLUCOSE-NEG KETONE-NEG BILIRUBIN-NEG UROBILNGN-NEG PH-5.0\n",
      "LEUK-NEG\n",
      "[**2107-1-17**] 12:47AM   LACTATE-1.3\n",
      "[**2107-1-22**] 03:07AM BLOOD WBC-7.5 RBC-2.85*# Hgb-8.6*# Hct-25.6*\n",
      "MCV-90 MCH-30.3 MCHC-33.6 RDW-14.4 Plt Ct-243\n",
      "[**2107-1-22**] 03:07AM BLOOD PT-22.4* PTT-31.1 INR(PT)-2.2*\n",
      "[**2107-1-22**] 03:07AM BLOOD Glucose-105 UreaN-11 Creat-0.6 Na-141\n",
      "K-4.0 Cl-102 HCO3-35* AnGap-8\n",
      "[**2107-1-22**] 03:07AM BLOOD Calcium-9.0 Phos-4.1 Mg-2.1\n",
      "[**2107-1-23**] 04:34PM BLOOD PEP-HYPOGAMMAG IgG-535* IgA-254 IgM-109\n",
      ".\n",
      "CTA chest:\n",
      "1. Interval development of patchy areas of consolidation with\n",
      "mucous plugging, particularly in the right lower lobe, right\n",
      "upper and mid lobes suggest a new infectious process or\n",
      "aspiration.\n",
      "2. Resolution of the previously identified pulmonary embolism.\n",
      "3. Extensive centrilobular and paraseptal emphysematous change.\n",
      "4. Fluid-attenuating structure adjacent to the right T11-12\n",
      "neural foramen is also unchanged and could be a perineural cyst.\n",
      ".\n",
      "CT abdomen/pelvis:\n",
      "1. New large hematoma in the muscles of the left anterior and\n",
      "lateral lower abdominal and pelvic wall, without any\n",
      "intraperitoneal or retroperitoneal extent, but with associated\n",
      "mass effect on the lower abdominal and pelvic bowel loops.\n",
      "2. Unchanged infectious or inflammatory opacities in the right\n",
      "middle and lower lobes.\n",
      ".\n",
      "[**2107-2-1**] IR Embolization: 1. Right inferior epigastric\n",
      "arteriogram demonstrates no extravasation of contrast and\n",
      "successful embolization with Gelfoam until stagnation of flow.\n",
      "2. The right internal mammary artery demonstrated no areas of\n",
      "active extravasation of contrast.\n",
      ".\n",
      "[**2107-2-3**] CXR: There is an irregular opacity in the right lower\n",
      "lobe\n",
      "concerning for pneumonia.  There are no pleural effusions.\n",
      "There is no\n",
      "pneumothorax.  The left subclavian catheter tip overlies the mid\n",
      "SVC.  Heart size normal.  Mediastinal and hilar contours are\n",
      "normal. IMPRESSION:  Opacity in the right lower lobe concerning\n",
      "for pneumonia.\n",
      ".\n",
      "[**2107-2-8**] LENIS: Extensive occlusive thrombus is demonstrated from\n",
      "the common femoral vein at the takeoff of the greater saphenous\n",
      "vein extending distally to the popliteal veins bilaterally.  No\n",
      "color flow, compressibility, or waveforms are demonstrated\n",
      "within these areas of thrombus. IMPRESSION:  Extensive,\n",
      "completely occlusive, bilateral deep venous thrombi extending\n",
      "from the common femoral veins to the popliteal veins.\n",
      ".\n",
      "[**2107-2-9**] ECG: Sinus tachycardia, Normal ECG except for rate\n",
      "\n",
      "\n",
      "Brief Hospital Course:\n",
      "64F w/ h/o recurrent PE s/[**Initials (NamePattern4) **] [**Last Name (NamePattern4) 260**] filter, GIB on\n",
      "anticoagulation, COPD, recently admitted for new PE, readmitted\n",
      "for multifocal PNA, who developed a large abdominal wall\n",
      "hematoma in the context of enoxaparin injections.\n",
      "\n",
      "# Multifocal Pneumonia: She was admitted with multifocal\n",
      "pneumonia. She was started on levofloxacin and vancomycin.  She\n",
      "completed a 7 day course of levofloxacin.  MRSA was found to\n",
      "grow in her sputum so she was continued on a 14 day course of\n",
      "vancomycin. She originally presented with elevated WBC count and\n",
      "left shift which quickly resolved with the initiation of\n",
      "antibiotics.  Her productive cough improved as well and she\n",
      "remained on her baseline home O2 of 2L.  Approximately 4 days\n",
      "after completion of her 14 day course of Vancomycin, the patient\n",
      "developed worsening cough, SOB, and upper respiratory symptoms.\n",
      "A repeat CXR showed evidence of a new consolidation in the RLL.\n",
      "The patient was started back on Levofloxacin/Flagyl.  Vancomycin\n",
      "was added to her regimen when blood cultures showed 2/4 bottles\n",
      "with GPC in clusters and chains.  Additionally, her sputum\n",
      "culture grew out GNRs.  Levofloxacin was discontinued and\n",
      "Meropenem was started for concern for Pseudomonas given the\n",
      "patient's long hospital course.  Her O2 sat remained stable\n",
      "93-100% on 2L nasal cannula (which is her baseline).  She was\n",
      "given mucomyst inhaled nebulizers to assist in breaking up thick\n",
      "sputum.  Her GNRs in the sputum grew out E. coli.  Because of\n",
      "the sensitivity profile of the E. coli and the patient's allergy\n",
      "to penicillin and cephalosporins, the patient was continued on\n",
      "Meropenem.  Her GPCs were found to grow out Coag negative Staph.\n",
      " Surveillance cultures had no further growth and the coag\n",
      "negative staph was thought to likely be a contaminant.  Her\n",
      "Vancomycin was discontinued.  She will continue a 14 day course\n",
      "of Meropenem and she was discharged with a PICC to complete this\n",
      "course.\n",
      ".\n",
      "# Pulmonary embolism/DVTs: She has had multiple PEs and has had\n",
      "one even since the placement of a TrapEase IVC filter. CT during\n",
      "recent previous hospitalization revealed appropriate location of\n",
      "filter and CTA on this admission showed improvement of clot.\n",
      "Admission labwork revealed an INR of 7.9.  Coumadin was thus\n",
      "held and reversed with FFP and vitamin K given her history of\n",
      "GIB on anticoagulation.  In the interim, therapeutic lovenox\n",
      "injections were initiated, but within days of starting, she\n",
      "developed a large abdominal wall hematoma near to lovenox\n",
      "injection site.  Once her hematocrit stabilized, she was started\n",
      "on a heparin gtt with coumadin overlap.  While [**Last Name (NamePattern4) 9533**] her\n",
      "Coumadin with an INR 1.2, she was found to have a large Hct drop\n",
      "and a CT scan of the abdomen showed a new rectus hematoma.  She\n",
      "was subsequently transferred to the MICU for closer monitoring.\n",
      "It was decided after her second hematoma while on\n",
      "anticoagulation, the risks of anticoagulation outweigh the\n",
      "benefits at this time and she was not anticoagulated.  In terms\n",
      "of her hypercoagulable workup, it has been negative thus far for\n",
      "hyperhomocysteinemia, Factor V Leiden and antiphospholipid\n",
      "antibody. Malignancy workup included a colonoscopy and EGD as\n",
      "well as CEA, all of which were within normal limits. SPEP\n",
      "revealed hypogammaglobulinemia, but was otherwise unremarkable.\n",
      "During her hospital course, she also began to complain of\n",
      "worsening lower extremity pain.  LENIs were obtained which\n",
      "showed evidence of extensive, completely occlusive, bilateral\n",
      "deep venous thrombi extending from the common femoral veins to\n",
      "the popliteal veins.  Radiology felt that these clots were most\n",
      "likely acute to subacute in nature.  In this setting,\n",
      "hematology/oncology saw the patient again to consider the risks\n",
      "vs benefits of anticoagulation.  Antithrombin III, prothrombin\n",
      "mutation, Lupus anticoagulation and [**Location (un) 1169**] Venom Viper were\n",
      "sent to reevaluate the reason for her hypercoagulability.  The\n",
      "hematology/oncology team still felt that the risks of\n",
      "coagulation outweigh the potential benefits given that the\n",
      "patient has had multiple bleeding episodes in the setting of\n",
      "anticoagulation.\n",
      "\n",
      "# Abdominal wall hematoma: As mentioned above, she developed a\n",
      "large left-sided abdominal wall hematoma from a Lovenox\n",
      "injection site that caused a significant hct drop (originally\n",
      "28.1-->19.4).  Despite the drop, she remained hemodynamically\n",
      "stable (has sinus tachycardia at baseline prior to bleed). She\n",
      "received 3 units prbcs, 4 units FFP. Her hematocrit then\n",
      "stabilized and once stable, she was restarted on heparin gtt.\n",
      "Coumadin was re-initiated and heparin gtt was continued while\n",
      "awaiting her INR to become therapeutic.  While [**Location (un) 9533**] her\n",
      "Coumadin with an INR 1.2, she was found to have another Hct drop\n",
      "(25.9-> 22.2) and a CT scan of the abdomen showed a new\n",
      "right-sided rectus hematoma.  She was subsequently transferred\n",
      "to the MICU for closer monitoring.  She was given 1 unit FFP and\n",
      "9 units PRBCs between [**Date range (1) 39125**] until her hematocrit became\n",
      "stable and she bumped appropriately to transfusion.  It was\n",
      "decided after her second hematoma while on anticoagulation, the\n",
      "risks of anticoagulation outweigh the benefits at this time and\n",
      "she was not anticoagulated.  She has complained of [**6-16**]\n",
      "abdominal pain with movement and has maintained stable\n",
      "hematocrits.  Her pain is most likely [**3-11**] to the large rectus\n",
      "hematoma that will resolve over time.  Her Hct remained stable\n",
      "after her anticoagulation was discontinued.\n",
      "\n",
      "# Thoracic mass:  CT chest and abdomen revealed a stable\n",
      "thoracic mass (stable x 3years) and thought potentially\n",
      "consistent with neural cyst.  It was not further evaluated by\n",
      "MRI given its long term stability and also she has metal\n",
      "hardware in place s/p elbow surgery and facial plates.  It\n",
      "should be followed up with imaging to ensure it remains\n",
      "unchanged in the future.\n",
      "\n",
      "# ? Zoster:  Patient reports having a history of \"herpes\" on her\n",
      "right buttock.  During her stay, she developed a tingling,\n",
      "itchiness and multiple small erythematous skin lesions on her\n",
      "right buttock over the S2, S3 dermatomal distribution.  There\n",
      "were no vesicles appreciated.  She was treated with acyclovir.\n",
      "\n",
      "# Candidal vaginitis:  Treated with fluconazole x 2 with\n",
      "resolution of symptoms.\n",
      "\n",
      "# H/o GI bleeding during recent admission: Recent colonoscopy\n",
      "showed diverticulosis with no active signs of bleeding.  She had\n",
      "no blood in her stools during this admission even while\n",
      "anticoagulated.  Her stools were guiac-ed multiple times and\n",
      "were found to be guiac negative.\n",
      "\n",
      "# Constipation: She is constipated at baseline and requires\n",
      "daily scheduled bowel regimen to maintian regularity.\n",
      "\n",
      "# Hyperlipidemia: Continued on lipitor.\n",
      "\n",
      "# Depression/SAD: Continued on Prozac, risperdone, wellbutrin,\n",
      "and klonopin.\n",
      "\n",
      "# Ulcerative Colitis: Remains in remission.  She was continued\n",
      "on mesalamine.\n",
      "\n",
      "# Orthostatic hypotension: She remained asymptomatic even while\n",
      "ambulating with physical therapy.  She was continued on\n",
      "midodrine.\n",
      "\n",
      "Medications on Admission:\n",
      "1. Fluoxetine 30 mg daily\n",
      "2. Risperidone 3 mg PO HS\n",
      "3. Bupropion SR 150 mg [**Hospital1 **]\n",
      "5. Nicotine 7 mg/24 hr Patch\n",
      "6. Hexavitamin daily\n",
      "7. ascorbic acid 500 tab 1 [**Hospital1 **]\n",
      "8. Calcium Carbonate 500 tab [**Hospital1 **]\n",
      "9. Ferrous gluconate 325 PO daily\n",
      "10. Atorvastatin 20 mg daily\n",
      "11. Fluticasone Salmeterol 250/50 [**Hospital1 **]\n",
      "12. Midodrine 5 mg tab 1 TID\n",
      "13. Tiotropium bromide capsule one cap /day\n",
      "14. Mesalamine 1200 TID\n",
      "15. Pantoprazole 40/ day\n",
      "16. Albuterol nebs prn (tid generally)\n",
      "17. docusate sodium\n",
      "18. Warfarin 5 mg/day\n",
      "19. Ipratropium nebs prn (tid generally)\n",
      "20. clonazepam 1mg po tid\n",
      "\n",
      "\n",
      "Discharge Medications:\n",
      "1. Fluoxetine 10 mg Capsule Sig: Three (3) Capsule PO DAILY\n",
      "(Daily).\n",
      "2. Risperidone 1 mg Tablet Sig: Three (3) Tablet PO HS (at\n",
      "bedtime).\n",
      "3. Bupropion 150 mg Tablet Sustained Release Sig: One (1) Tablet\n",
      "Sustained Release PO BID (2 times a day).\n",
      "4. Hexavitamin     Tablet Sig: One (1) Cap PO DAILY (Daily).\n",
      "5. Calcium Carbonate 500 mg Tablet, Chewable Sig: One (1)\n",
      "Tablet, Chewable PO BID (2 times a day).\n",
      "6. Fluticasone-Salmeterol 250-50 mcg/Dose Disk with Device Sig:\n",
      "One (1) Disk with Device Inhalation [**Hospital1 **] (2 times a day).\n",
      "7. Midodrine 5 mg Tablet Sig: One (1) Tablet PO TID (3 times a\n",
      "day).\n",
      "8. Mesalamine 400 mg Tablet, Delayed Release (E.C.) Sig: Three\n",
      "(3) Tablet, Delayed Release (E.C.) PO TID (3 times a day).\n",
      "9. Pantoprazole 40 mg Tablet, Delayed Release (E.C.) Sig: One\n",
      "(1) Tablet, Delayed Release (E.C.) PO Q24H (every 24 hours).\n",
      "10. Docusate Sodium 100 mg Capsule Sig: One (1) Capsule PO BID\n",
      "(2 times a day).\n",
      "11. Nicotine 7 mg/24 hr Patch 24HR Sig: One (1) Patch 24HR\n",
      "Transdermal DAILY (Daily).\n",
      "12. Ferrous Gluconate 300 mg Tablet Sig: One (1) Tablet PO DAILY\n",
      "(Daily): please do not take this with levofloxacin.\n",
      "13. Cepacol 2 mg Lozenge Sig: One (1) Lozenge Mucous membrane\n",
      "Q4H (every 4 hours) as needed.\n",
      "Disp:*100 Lozenge(s)* Refills:*0*\n",
      "14. Tiotropium Bromide 18 mcg Capsule, w/Inhalation Device Sig:\n",
      "One (1) Cap Inhalation DAILY (Daily).\n",
      "15. Sodium Chloride 0.65 % Aerosol, Spray Sig: [**2-8**] Sprays Nasal\n",
      "QID (4 times a day).\n",
      "Disp:*QS bottle* Refills:*2*\n",
      "16. Senna 8.6 mg Tablet Sig: One (1) Tablet PO BID (2 times a\n",
      "day).\n",
      "Disp:*60 Tablet(s)* Refills:*2*\n",
      "17. Clonazepam 1 mg Tablet Sig: One (1) Tablet PO TID (3 times a\n",
      "day) as needed for anxiety.\n",
      "Disp:*20 Tablet(s)* Refills:*0*\n",
      "18. Saline Flush 0.9 % Syringe Sig: Three (3) ml Injection twice\n",
      "a day for 20 doses: prior to each vanco dose.\n",
      "Disp:*20 syringe* Refills:*0*\n",
      "19. Docusate Sodium 100 mg Capsule Sig: One (1) Capsule PO twice\n",
      "a day.\n",
      "20. Simethicone 80 mg Tablet, Chewable Sig: One (1) Tablet,\n",
      "Chewable PO QID (4 times a day) as needed.\n",
      "21. Aluminum-Magnesium Hydroxide 225-200 mg/5 mL Suspension Sig:\n",
      "15-30 MLs PO QID (4 times a day) as needed.\n",
      "22. Bisacodyl 5 mg Tablet, Delayed Release (E.C.) Sig: Two (2)\n",
      "Tablet, Delayed Release (E.C.) PO DAILY (Daily) as needed for\n",
      "constipation.\n",
      "23. Oxycodone 5 mg Tablet Sig: 1-2 Tablets PO Q4-6H (every 4 to\n",
      "6 hours) as needed for pain.\n",
      "24. Lidocaine 5 %(700 mg/patch) Adhesive Patch, Medicated Sig:\n",
      "One (1) Adhesive Patch, Medicated Topical QD ().\n",
      "25. \n"
     ]
    }
   ],
   "source": [
    "print(txt_str[:17279])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "72241fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Drug', 'start': 17279, 'end': 17291, 'value': 'Pantoprazole'}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent['T277']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "506e6655",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sentence'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[150], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m e, v \u001b[39min\u001b[39;00m ent\u001b[39m.\u001b[39mitems():\n\u001b[1;32m----> 2\u001b[0m     v[\u001b[39m'\u001b[39;49m\u001b[39msentence\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'sentence'"
     ]
    }
   ],
   "source": [
    "for e, v in ent.items():\n",
    "    v['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "49ce42ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sentence'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[144], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rel_spans \u001b[39m=\u001b[39m get_relationship_spans(ent, rel, txt_str)\n",
      "Cell \u001b[1;32mIn[140], line 77\u001b[0m, in \u001b[0;36mget_relationship_spans\u001b[1;34m(entities, relationships, txt_str)\u001b[0m\n\u001b[0;32m     75\u001b[0m arg1 \u001b[39m=\u001b[39m entities[relationship[\u001b[39m'\u001b[39m\u001b[39marg1\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m     76\u001b[0m arg2 \u001b[39m=\u001b[39m entities[relationship[\u001b[39m'\u001b[39m\u001b[39marg2\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m---> 77\u001b[0m \u001b[39mif\u001b[39;00m arg1[\u001b[39m'\u001b[39;49m\u001b[39msentence\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m arg2[\u001b[39m'\u001b[39m\u001b[39msentence\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m     78\u001b[0m     sent_start \u001b[39m=\u001b[39m arg1[\u001b[39m'\u001b[39m\u001b[39msentence\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     79\u001b[0m     sent_end \u001b[39m=\u001b[39m arg2[\u001b[39m'\u001b[39m\u001b[39msentence\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'sentence'"
     ]
    }
   ],
   "source": [
    "rel_spans = get_relationship_spans(ent, rel, txt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2f908b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#',\n",
       " 'Ventilator',\n",
       " 'associated',\n",
       " 'pneumonia',\n",
       " ':',\n",
       " 'Patient',\n",
       " 'developed',\n",
       " 'a',\n",
       " 'fever',\n",
       " 'on',\n",
       " '[',\n",
       " '*',\n",
       " '*',\n",
       " '2-27',\n",
       " '*',\n",
       " '*',\n",
       " ']',\n",
       " 'with',\n",
       " 'new',\n",
       " 'infiltrates',\n",
       " 'on',\n",
       " 'chest',\n",
       " 'xray',\n",
       " 'while',\n",
       " 'intubated',\n",
       " '.',\n",
       " 'He',\n",
       " 'was',\n",
       " 'initially',\n",
       " 'covered',\n",
       " 'with',\n",
       " 'vanc/cefepime',\n",
       " 'and',\n",
       " 'cipro',\n",
       " '.']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b9954ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Ventilator associated pneumonia:  Patient developed a fever on\\n[**2-27**] with new infiltrates on chest xray while intubated. He was\\ninitially covered with vanc/cefepime and cipro.'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b4d70688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/cefepim'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[162:170]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "abe9089e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmin of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[105], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m df_rel_lst \u001b[39m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m i, (s, v) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(rel_spans\u001b[39m.\u001b[39mitems()):\n\u001b[1;32m----> 4\u001b[0m     df1, df2 \u001b[39m=\u001b[39m get_token_tags(s, v[\u001b[39m'\u001b[39;49m\u001b[39mall_entities\u001b[39;49m\u001b[39m'\u001b[39;49m], v[\u001b[39m'\u001b[39;49m\u001b[39mrelationships\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      5\u001b[0m     df1[\u001b[39m'\u001b[39m\u001b[39msid\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m i\n\u001b[0;32m      6\u001b[0m     df1[\u001b[39m'\u001b[39m\u001b[39mcontains_rel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[98], line 195\u001b[0m, in \u001b[0;36mget_token_tags\u001b[1;34m(text, all_ents, all_rels)\u001b[0m\n\u001b[0;32m    193\u001b[0m ent_dict \u001b[39m=\u001b[39m {}\n\u001b[0;32m    194\u001b[0m \u001b[39mfor\u001b[39;00m eid, val \u001b[39min\u001b[39;00m all_ents\u001b[39m.\u001b[39mitems():\n\u001b[1;32m--> 195\u001b[0m     tmp, s_idx, e_idx \u001b[39m=\u001b[39m tag_index(\n\u001b[0;32m    196\u001b[0m         text, val[\u001b[39m'\u001b[39;49m\u001b[39mtype\u001b[39;49m\u001b[39m'\u001b[39;49m], val[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m], val[\u001b[39m'\u001b[39;49m\u001b[39mstart_pos\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m    197\u001b[0m     )\n\u001b[0;32m    198\u001b[0m     tag_dict \u001b[39m=\u001b[39m tag_dict \u001b[39m|\u001b[39m tmp\n\u001b[0;32m    199\u001b[0m     ent_dict[eid] \u001b[39m=\u001b[39m {\n\u001b[0;32m    200\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mstart_idx\u001b[39m\u001b[39m'\u001b[39m: s_idx,\n\u001b[0;32m    201\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mend_idx\u001b[39m\u001b[39m'\u001b[39m: e_idx\n\u001b[0;32m    202\u001b[0m     }\n",
      "Cell \u001b[1;32mIn[98], line 172\u001b[0m, in \u001b[0;36mtag_index\u001b[1;34m(text, ent_type, ent_text, ent_loc)\u001b[0m\n\u001b[0;32m    170\u001b[0m ent_tokens \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39mword_tokenize(ent_text)\n\u001b[0;32m    171\u001b[0m possible_loc \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(tokens\u001b[39m==\u001b[39ment_tokens[\u001b[39m0\u001b[39m])[\u001b[39m0\u001b[39m]\n\u001b[1;32m--> 172\u001b[0m ent_start_loc \u001b[39m=\u001b[39m possible_loc[np\u001b[39m.\u001b[39;49margmin(\n\u001b[0;32m    173\u001b[0m     [\u001b[39mabs\u001b[39;49m(ent_loc \u001b[39m-\u001b[39;49m \u001b[39mlen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(tokens[\u001b[39m0\u001b[39;49m:x]))) \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m possible_loc]\n\u001b[0;32m    174\u001b[0m )]\n\u001b[0;32m    175\u001b[0m ent_end_loc \u001b[39m=\u001b[39m ent_start_loc \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(ent_tokens) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    176\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(ent_tokens) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36margmin\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Meet\\miniconda3\\envs\\myenv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1338\u001b[0m, in \u001b[0;36margmin\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1251\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1252\u001b[0m \u001b[39mReturns the indices of the minimum values along an axis.\u001b[39;00m\n\u001b[0;32m   1253\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1335\u001b[0m \u001b[39m(2, 1, 4)\u001b[39;00m\n\u001b[0;32m   1336\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1337\u001b[0m kwds \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mkeepdims\u001b[39m\u001b[39m'\u001b[39m: keepdims} \u001b[39mif\u001b[39;00m keepdims \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39m_NoValue \u001b[39melse\u001b[39;00m {}\n\u001b[1;32m-> 1338\u001b[0m \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39m\u001b[39margmin\u001b[39m\u001b[39m'\u001b[39m, axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\Meet\\miniconda3\\envs\\myenv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:54\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     52\u001b[0m bound \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(obj, method, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m     53\u001b[0m \u001b[39mif\u001b[39;00m bound \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\Meet\\miniconda3\\envs\\myenv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:43\u001b[0m, in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m     wrap \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(asarray(obj), method)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     44\u001b[0m \u001b[39mif\u001b[39;00m wrap:\n\u001b[0;32m     45\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(result, mu\u001b[39m.\u001b[39mndarray):\n",
      "\u001b[1;31mValueError\u001b[0m: attempt to get argmin of an empty sequence"
     ]
    }
   ],
   "source": [
    "df_ner_lst = []\n",
    "df_rel_lst = []\n",
    "for i, (s, v) in enumerate(rel_spans.items()):\n",
    "    df1, df2 = get_token_tags(s, v['all_entities'], v['relationships'])\n",
    "    df1['sid'] = i\n",
    "    df1['contains_rel'] = 1\n",
    "    df2['sid'] = i\n",
    "    df_ner_lst.append(df1)\n",
    "    df_rel_lst.append(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a3c2c34c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R1': {'type': 'Duration-Drug',\n",
       "  'arg1': 'T1',\n",
       "  'arg1_start': 5,\n",
       "  'arg1_end': 5,\n",
       "  'arg2': 'T2',\n",
       "  'arg2_start': 8,\n",
       "  'arg2_end': 8}}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_token_tags(s, rel_spans[s]['all_entities'], rel_spans[s]['relationships'])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c4c58714",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncovered_ent_spans = get_uncovered_entity_spans(ent, rel, txt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "359ecfc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The patient had persistent symptoms and was\\nstarted on levofloxacin by his PCP two days prior to admission.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = list(uncovered_ent_spans.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "740a7f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'O'),\n",
       " ('patient', 'O'),\n",
       " ('had', 'O'),\n",
       " ('persistent', 'O'),\n",
       " ('symptoms', 'O'),\n",
       " ('and', 'O'),\n",
       " ('was', 'O'),\n",
       " ('started', 'O'),\n",
       " ('on', 'O'),\n",
       " ('levofloxacin', 'S-Drug'),\n",
       " ('by', 'O'),\n",
       " ('his', 'O'),\n",
       " ('PCP', 'O'),\n",
       " ('two', 'O'),\n",
       " ('days', 'O'),\n",
       " ('prior', 'O'),\n",
       " ('to', 'O'),\n",
       " ('admission', 'O'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_token_tags(s1, uncovered_ent_spans[s1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2357efbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "26128e264d228505edcdd079c0afd2b8cc37c9a8b8aeae9abc308e3b38af8b3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
